\section{Motivação}
O desenvolvimento e utilização de modelos matemáticos e computacionais deve encompassar as seguintes etapas: 
verificação, validação, calibração, análise de incerteza e análise de sensibilidade.

As duas primeiras etapas estão historicamente 
muito interligadas, e costumam ser referidas como V \& V: a verificação consiste em garantir que o código 
computacional implemente o modelo desejado, enquanto a validação consiste em garantir que o modelo teórico é capaz de 
reproduzir os fênomenos reais desejados. Outra forma de pensar e V \& V é que a validação se ocupa em determinar
que o modelo está resolvendo as equações certas, enquanto a verificação se ocupa em determinar se o modelo está
resolvendo as equações corretamente \citep{ASC2010}.
Questões relacionadas a verificação de modelos não costumam ser formuladas estatisticamente, então não serão tratadas aqui.

A calibração consiste em ajustar os parâmetros implementados no código para melhorar a concordância entre o resultado
obtido pelo modelo e aquele observado em uma determinada situação. A correta calibração de um modelo é considerada
essencial para que o modelo possa ser considerado para fins preditivos \citep{ASC2010}.

As duas últimas etapas já foram extensamente discutidas no capítulo \ref{cap:pse}, mas é importante frisar que
é geralmente aceito que a
calibração e as análises de incerteza e sensibilidade dependem fortemente da realização prévia de verificação e 
validação do modelo.

Durante o desenvolvimento e a análise de modelos matemáticos em ecologia, é comum separar a calibração por 
estimativa dos parâmetros (EP)
da análise de incerteza e sensibilidade (AIS) do modelo. Os dois passos são feitos em seções diferentes dos artigos, discutidos
em capítulos diferentes dos livros \citep{Caswell89}, e frequentemente realizados por equipes diferentes. Em estudos que 
empregam modelos matriciais, a discussão dos resultados se concentra no ponto obtido por uma combinação 
de parâmetros considerada ótima durante as estimativas de parâmetros \citep{SilvaMatos99}, e a análise de incerteza é apresentada
como um procedimento separado e posterior à análise do resultado considerado como principal. 
Até mesmo a abordagem estatística usada em ambos os procedimentos pode ser incoerente.

Outro problema que surge nessa abordagem é o fato de que, muitas vezes, o conjunto de parâmetros usados na calibração do modelo
tem pouca relação com as entradas individuais da matriz de projeção. Isso ocorre, por exemplo, quando séries temporais
da população são utilizadas para estimar as taxas vitais: nesse caso, o responsável pela calibração vê o sistema como
contagens de indivíduos, enquanto o responsável pela análise de incerteza tipicamente realiza a análise sobre as taxas vitais.
Desta forma, a AIS é incapaz de apontar rumos para o planejamento de novos experimentos, apontando quais parâmetros 
devem ser alvo de maior esforço de coleta.

Essa falta de integração entre os passos necessários para o estudo de um modelo tem suas raízes no 
desenvolvimento das teorias de EP e AIS. Enquanto a estimação de parâmetros sempre foi tratada sob o ponto de vista
de uma teoria estatística, a análise de sensibilidade de modelos matriciais foi desenvolvida como 
uma ferramenta analítica, baseada em expansões lineares das funções de interesse em torno de um ponto privilegiado. 
Dependendo do tipo de experimento utilizado para obter estimativas das taxas vitais, diferentes abordagens 
podem ser utilizadas para encontrar um conjunto de valores que melhor represente o estado de conhecimento
que temos de uma população, entre abordagens frequentistas, bayesianas ou baseadas em verossimilhança.
Já a teoria analítica de AIS, devida em grande parte aos trabalhos de Hal Caswell \citep{Caswell89}, procede rotineiramente por
tomar um modelo já parametrizado da forma ótima, e estudar as derivadas de primeira ordem da resposta de interesse
em relação a cada um dos parâmetros de entrada. Nessa formulação, a quantidade e a qualidade dos dados de entrada
para o modelo são ignorados, a menos de suas médias, e medidas de sensibilidade são tomadas exclusivamente sobre
a variação da resposta de interesse a perturbações infinitesimais. Desta forma, modelos parametrizados com dados
com grande incerteza não apresentarão grandes medidas de sensibilidade, assim como aumentar o esforço amostral não
reduzirá necessariamente as medidas de incerteza. A análise de sensibilidade analítica, em última análise, diz
respeito à estrutura do modelo matricial, e não ao procedimento completo desde a tomada de dados em campo até
a formulação e execução do modelo. Isso pode levar a uma falsa confiança em estudos que apresentem
uma estrutura matricial estável, portanto de baixas sensibilidades, mas dados tomados com muita incerteza.

Por outro lado, questões de validação dos modelos são frequentemente menosprezadas pela literatura da área,
apesar de estarem intimamente conectadas com as questões relevantes de incerteza. Podemos dividir a incerteza
de um modelo em três fontes principais: incerteza estrutural, incerteza de parâmetros (ou epistêmica) 
e incerteza estocástica. Enquanto a maioria das técnicas de AIS se concentram na segunda componente, 
a validação de modelos pode apontar qual o nível de confiança que podemos ter de que um dado modelo é
o modelo correto para reproduzir o fenômeno visto.

A formulação estocástica da teoria de análise de incerteza e sensibilidade global, interpretada dentro de uma
abordagem pautada pelo princípio da verossimilhança, é capaz de contemplar da mesma forma todas as fontes de 
incerteza descritas acima, gerando como resultado um quadro completo do nosso conhecimento a respeito de 
um sistema. Embora para sistemas muito simples as abordagens possam convergir, isso não se verifica para problemas
e sistemas de maior complexidade. As principais vantagens de usar a formulação estocástica são:

\begin{enumerate}
	\item A abordagem analítica é local (portanto, responde ao que acontece com perturbações infinitesimais) 
		e depende das funções serem "suaves" na vizinhança, a estocástica é global e não tem essa limitação.
	\item O princípio de verossimilhança afirma que toda a informação contida nas amostras coletadas está contida 
		na função de verossimilhança. Dessa forma, a análise de sensibilidade feita a partir da função de 
		verossimilhança contém toda a informação obtida pela amostra e nenhuma informação além da obtida pela 
		amostra - enquanto a abordagem analítica pode, alternadamente, desperdiçar informações coletadas ou 
		levar à falsa impressão de gerar respostas com maior precisão do que a informação coletada permite.
\end{enumerate}

%(********* DESENVOLVER O ARGUMENTO SOBRE INFORMAÇÃO DE FISHER AQUI *************)

\begin{shaded}
\section{Uma função de suporte}
Ao falar da análise de incerteza de um modelo matemático sob o paradigma da verossimilhança, a pergunta que estamos
fazendo pode ser escrita como: ``qual o suporte que existe para hipóteses concorrentes a respeito do resultado de um
modelo, a partir de um conjunto de dados coletados?''. Em um modelo de crescimento populacional, por exemplo, a pergunta
se torna ``qual o suporte que os dados coletados fornecem para a hipótese de que a população está crescendo ou estável,
{\em versus} a hipótese de que a população está em declínio?''.

Sabemos que essa pergunta, se formulada sobre os parâmetros
de uma distribuição de probabilidade, é respondida através da função de verossimilhança. Também sabemos que
transformações injetoras sobre parâmetros preservam as propriedades da função de verossimilhança, isso é: 
se um parâmetro $\theta$ está associado a uma função de verossimilhança $\mathcal{L}(\theta|\bu{x})$ e 
$\phi = f(\theta)$ é dada por uma função $f(\cdot)$ injetora, a verossimilhança de $\phi$ é dada simplesmente por
$\mathcal{L}(\phi|\bu{x}) = \mathcal{L} \left(f(\theta)|\bu{x}\right)$ (\citep{Edwards72}, sec. 2.5).

Nosso trabalho, então, é o de estender esse resultado para uma função genérica. 
Nosso argumento se baseia em uma função de um argumento, $\gamma = g(\theta)$, sendo que a generalização 
para mais dimensões é trivial.\footnote{A notação usada aqui é mais compatível com a literatura estatística,
enquanto na sessão \ref{PSE}, definimos as entradas, resultados e o modelo em si como $x$, $y$ e $f$, relacionados
como $y = f(x)$, aqui podemos pensar nesses objetos como $\theta$, $\gamma$ e $g$, respectivamente.}

O problema de definição de uma verossimilhança para análise de incerteza em modelos está, portanto, intimamente ligada à questão
de hipóteses compostas sob o paradigma da verossimilhança. O trabalho fundamental de Neyman e Pearson \citep{Neyman1933}
estabelece uma justificativa matemática para o princípio da verossimilhança em problemas envolvendo hipóteses simples.
O problema de hipóteses compostas é resolvido dentro do paradigma frequentista para alguns casos particulares, como 
o teste {\em t de Student}, que avalia a hipótese nula de que a média de duas populações é igual, sendo a variância um 
parâmetro desconhecido.

ROYALL SESSAO 1.9

%http://www.tandfonline.com/doi/abs/10.1080/00949657208810001?journalCode=gscs20#.Uv_UEJjTi00
%http://biomet.oxfordjournals.org/content/62/2/451.short

Vamos construir uma função de verossimilhança $\Psi (\gamma | \bu{x})$, definida por:

\begin{equation}
	\Psi ( \gamma | \bu{x} ) = \sup\limits_{g(\theta) = \gamma} \mathcal{L} (\theta | \bu{x})
\label{eqn:Psi}
\end{equation}

E agora vamos demonstrar que essa função possui as seguintes propriedades de uma função de 
medida de suporte (ver \citep{Edwards72}, sec. 3.2):

\begin{enumerate}
	\item {\em Transitividade}.
	\item {\em Aditividade em relação aos dados}.
	\item {\em Invariância a transformações dos dados}.
	\item {\em Invariância a transformações dos parâmetros}. Não se mantém.
	\item {\em Relevância e consistência}.
	\item {\em Compatibilidade}.
\end{enumerate}

Para clarificar nossa operação, vamos construir uma outra função a partir de $\mathcal{L}(\theta|\bu{x})$ que 
\textbf{não} é função de verossimilhança: $\Psi^\dagger (\gamma | \bu{x})$, definida por:
\begin{equation}
\Psi^\dagger ( \gamma | \bu{x} ) = \int\limits_{g(\theta) = \gamma} \mathcal{L} (\theta | \bu{x}) \,d\theta
\label{eqn:Psistar}
\end{equation}

Intuitivamente, podemos considerar que se dois valores de $\theta$ levam a um mesmo valor de $\gamma$, a equação \ref{eqn:Psistar}
nos diz que o suporte para esse valor de $\gamma$ seria a soma do suporte dado aos valores de $\theta$. No entanto, a 
verossimilhança, ao contrário da probabilidade, não é aditiva em relação ao parâmetro, de forma de a função $\Psi^\dagger$ 
não é uma função de verossimilhança:

``No special meaning attaches to any part of the area under a likelihood curve, or to the sum of the likelihoods of two or more
hypotheses (...).
Altough the likelihood function, and hence the curve, has the mathematical form of a [known] distribution, it does not
represent a statistical distribution in any sense.'' \citep{Edwards72}

Do ponto de vista Bayesiano, podemos enxergar a função de probabilidade {\em a posteriori} de $\gamma$ como:


O que explica porque a propriedade de invariância a transformações nos parâmetros não é mantida por
uma transformação não-injetora.

Statistical Evidence: A Likelihood Paradigm page 8
%http://books.google.com.br/books?hl=en&lr=&id=oysWLTFaI_gC&oi=fnd&pg=PR11&dq=likelihood+composite+hypothesis&ots=W4nyN4-x84&sig=vjdFL8YrtFct4cOM_F_PFkznTwU&redir_esc=y#v=onepage&q&f=false

DÁ PRA USAR O MIDDLE-WAY DO FITELSON EM UA?


\section{Aplicação}
(****** vou explicar o passo a passo detalhadamente, aqui vai um resumão da aplicação *******)

Resumo de aplicação:
\begin{enumerate}
	\item Formule diferentes modelos para explicar seus dados (ex, fertilidade constante ou agrupada, taxa de crescimento constante ou descrescente com a classe de tamanho, modelo com 4 ou com 5 classes de tamanho, etc). Escreva a função de verossimilhança $L_i(\bu{\theta}|\bu{x})$ para cada modelo $i \in 1,...,n$.
	\item Encontre o conjunto de parâmetros que melhor ajusta seus dados para cada modelo. 
	\item Determine o valor de AIC para cada modelo. 
	\item Caso haja um modelo cujo desempenho é inequivocamente superior, use o método de Metropolis (forma de Monte Carlo) para gerar amostras a partir da função de verossimilhança do modelo, de acordo com a equação \ref{eqn:Psi}. 
	\item Caso haja um empate entre modelos, gere amostras a partir de todos os modelos vencedores e as combine usando os pesos designados pela diferença de informação (ver \citep{Edwards72}, teorema 5.4.2?).
	\item Realize as análises de incerteza e sensibilidade a partir dos resultados gerados.
\end{enumerate}
\end{shaded}

