\section{Motivação}
O desenvolvimento e utilização de modelos matemáticos e computacionais deve encompassar as seguintes etapas: 
verificação, validação, calibração, análise de incerteza e análise de sensibilidade.

As duas primeiras etapas estão historicamente 
muito interligadas, e costumam ser referidas como V \& V: a verificação consiste em garantir que o código 
computacional implemente o modelo desejado, enquanto a validação consiste em garantir que o modelo teórico é capaz de 
reproduzir os fênomenos reais desejados. Outra forma de pensar e V \& V é que a validação se ocupa em determinar
que o modelo está resolvendo as equações certas, enquanto a verificação se ocupa em determinar se o modelo está
resolvendo as equações corretamente \citep{ASC2010}.
Questões relacionadas a verificação de modelos não costumam ser formuladas estatisticamente, então não serão tratadas aqui.

A calibração consiste em ajustar os parâmetros implementados no código para melhorar a concordância entre o resultado
obtido pelo modelo e aquele observado em uma determinada situação. A correta calibração de um modelo é considerada
essencial para que o modelo possa ser considerado para fins preditivos \citep{ASC2010}.

As duas últimas etapas já foram extensamente discutidas no capítulo \ref{cap:pse}, mas é importante frisar que
é geralmente aceito que a
calibração e as análises de incerteza e sensibilidade dependem fortemente da realização prévia de verificação e 
validação do modelo.

Durante o desenvolvimento e a análise de modelos matemáticos em ecologia, é comum separar a calibração por 
estimativa dos parâmetros (EP)
da análise de incerteza e sensibilidade (AIS) do modelo. Os dois passos são feitos em seções diferentes dos artigos, discutidos
em capítulos diferentes dos livros \citep{Caswell89}, e frequentemente realizados por equipes diferentes. Em estudos que 
empregam modelos matriciais, a discussão dos resultados se concentra no ponto obtido por uma combinação 
de parâmetros considerada ótima durante as estimativas de parâmetros \citep{SilvaMatos99}, e a análise de incerteza é apresentada
como um procedimento separado e posterior à análise do resultado considerado como principal. 
Até mesmo a abordagem estatística usada em ambos os procedimentos pode ser incoerente.

Outro problema que surge nessa abordagem é o fato de que, muitas vezes, o conjunto de parâmetros usados na calibração do modelo
tem pouca relação com as entradas individuais da matriz de projeção. Isso ocorre, por exemplo, quando séries temporais
da população são utilizadas para estimar as taxas vitais: nesse caso, o responsável pela calibração vê o sistema como
contagens de indivíduos, enquanto o responsável pela análise de incerteza tipicamente realiza a análise sobre as taxas vitais.
Desta forma, a AIS é incapaz de apontar rumos para o planejamento de novos experimentos, apontando quais parâmetros 
devem ser alvo de maior esforço de coleta.

Essa falta de integração entre os passos necessários para o estudo de um modelo tem suas raízes no 
desenvolvimento das teorias de EP e AIS. Enquanto a estimação de parâmetros sempre foi tratada sob o ponto de vista
de uma teoria estatística, a análise de sensibilidade de modelos matriciais foi desenvolvida como 
uma ferramenta analítica, baseada em expansões lineares das funções de interesse em torno de um ponto privilegiado. 
Dependendo do tipo de experimento utilizado para obter estimativas das taxas vitais, diferentes abordagens 
podem ser utilizadas para encontrar um conjunto de valores que melhor represente o estado de conhecimento
que temos de uma população, entre abordagens frequentistas, bayesianas ou baseadas em verossimilhança.
Já a teoria analítica de AIS, devida em grande parte aos trabalhos de Hal Caswell \citep{Caswell89}, procede rotineiramente por
tomar um modelo já parametrizado da forma ótima, e estudar as derivadas de primeira ordem da resposta de interesse
em relação a cada um dos parâmetros de entrada. Nessa formulação, a quantidade e a qualidade dos dados de entrada
para o modelo são ignorados, a menos de suas médias, e medidas de sensibilidade são tomadas exclusivamente sobre
a variação da resposta de interesse a perturbações infinitesimais. Desta forma, modelos parametrizados com dados
com grande incerteza não apresentarão grandes medidas de sensibilidade, assim como aumentar o esforço amostral não
reduzirá necessariamente as medidas de incerteza. A análise de sensibilidade analítica, em última análise, diz
respeito à estrutura do modelo matricial, e não ao procedimento completo desde a tomada de dados em campo até
a formulação e execução do modelo. Isso pode levar a uma falsa confiança em estudos que apresentem
uma estrutura matricial estável, portanto de baixas sensibilidades, mas dados tomados com muita incerteza.

Por outro lado, questões de validação dos modelos são frequentemente menosprezadas pela literatura da área,
apesar de estarem intimamente conectadas com as questões relevantes de incerteza. Podemos dividir a incerteza
de um modelo em três fontes principais: incerteza estrutural, incerteza de parâmetros (ou epistêmica) 
e incerteza estocástica. Enquanto a maioria das técnicas de AIS se concentram na segunda componente, 
a validação de modelos pode apontar qual o nível de confiança que podemos ter de que um dado modelo é
o modelo correto para reproduzir o fenômeno visto.

A formulação estocástica da teoria de análise de incerteza e sensibilidade global, interpretada dentro de uma
abordagem pautada pelo princípio da verossimilhança, é capaz de contemplar da mesma forma todas as fontes de 
incerteza descritas acima, gerando como resultado um quadro completo do nosso conhecimento a respeito de 
um sistema. Embora para sistemas muito simples as abordagens possam convergir, isso não se verifica para problemas
e sistemas de maior complexidade. As principais vantagens de usar a formulação estocástica são:

\begin{enumerate}
	\item A abordagem analítica é local (portanto, responde ao que acontece com perturbações infinitesimais) 
		e depende das funções serem "suaves" na vizinhança, a estocástica é global e não tem essa limitação.
	\item O princípio de verossimilhança afirma que toda a informação contida nas amostras coletadas está contida 
		na função de verossimilhança. Dessa forma, a análise de sensibilidade feita a partir da função de 
		verossimilhança contém toda a informação obtida pela amostra e nenhuma informação além da obtida pela 
		amostra - enquanto a abordagem analítica pode, alternadamente, desperdiçar informações coletadas ou 
		levar à falsa impressão de gerar respostas com maior precisão do que a informação coletada permite.
\end{enumerate}

\section{Uma função de suporte}
Ao falar da análise de incerteza de um modelo matemático sob o paradigma da verossimilhança, a pergunta que estamos
fazendo pode ser escrita como: ``qual o suporte que existe para hipóteses concorrentes a respeito do resultado de um
modelo, a partir de um conjunto de dados coletados?''. Em um modelo de crescimento populacional, por exemplo, a pergunta
se torna ``qual o suporte que os dados coletados fornecem para a hipótese de que a população está crescendo ou estável,
{\em versus} a hipótese de que a população está em declínio?''.

Sabemos que essa pergunta, se formulada sobre os parâmetros
de uma distribuição de probabilidade, é respondida através da função de verossimilhança. Também sabemos que
transformações injetoras sobre parâmetros preservam as propriedades da função de verossimilhança, isso é: 
se um parâmetro $\theta$ está associado a uma função de verossimilhança $\mathcal{L}(\theta|\bu{x})$ e 
$\phi = f(\theta)$ é dada por uma função $f(\cdot)$ injetora, a verossimilhança de $\phi$ é dada simplesmente por
$\mathcal{L}(\phi|\bu{x}) = \mathcal{L} \left(f(\theta)|\bu{x}\right)$ (\citep{Edwards72}, sec. 2.5).

Nosso trabalho, então, é o de estender esse resultado para uma função genérica. 
Nosso argumento se baseia em uma função de um argumento, $\gamma = g(\theta)$, sendo que a generalização 
para mais dimensões é trivial.\footnote{A notação usada aqui é mais compatível com a literatura estatística,
enquanto na sessão \ref{PSE}, definimos as entradas, resultados e o modelo em si como $x$, $y$ e $f$, relacionados
como $y = f(x)$, aqui podemos pensar nesses objetos como $\theta$, $\gamma$ e $g$, respectivamente.}

O problema de definição de uma verossimilhança para análise de incerteza em modelos está, portanto, intimamente ligada à questão
de hipóteses estatísticas compostas. O trabalho fundamental de Neyman e Pearson \citep{Neyman1933}
estabelece uma justificativa matemática para o princípio da verossimilhança em problemas envolvendo hipóteses simples.
O problema de hipóteses compostas é resolvido dentro do paradigma frequentista para alguns casos particulares, como 
o teste {\em t de Student}, que avalia a hipótese nula de que a média de duas populações é igual, sendo a variância um 
parâmetro desconhecido. Estatísticos frequentistas tratam o problema de hipóteses compostas através do máximo de
verossimilhança obtido por qualquer de suas hipóteses simples componentes. Muito do trabalho nessa área se concentrará
em encontrar aproximações para a distribuição dessa estatística \citep{Wilks38}.

Sob esta inspiração, vamos construir uma função tentativa de suporte $\Psi^\delta (\gamma | \bu{x})$, definida por:

\begin{equation}
	\Psi^\delta ( \gamma | \bu{x} ) = \sup\limits_{g(\theta) = \gamma} \mathcal{L} (\theta | \bu{x})
\label{eqn:Psidelta}
\end{equation}

Essa função pode ser intuitivamente interpretada no sentido de equiparar a verossimilhança da hipótese composta com
a da sua melhor hipótese simples componente.
Para clarificar nossa operação, vamos construir uma outra função a partir de $\mathcal{L}(\theta|\bu{x})$ que 
\textbf{não} é função de verossimilhança: $\Psi^\dagger (\gamma | \bu{x})$, definida por:
\begin{equation}
\Psi^\dagger ( \gamma | \bu{x} ) = \int\limits_{g(\theta) = \gamma} \mathcal{L} (\theta | \bu{x}) \,d\theta
\label{eqn:Psistar}
\end{equation}

Intuitivamente, podemos considerar que se dois valores de $\theta$ levam a um mesmo valor de $\gamma$, a equação \ref{eqn:Psistar}
nos diz que o suporte para esse valor de $\gamma$ seria a soma do suporte dado aos valores de $\theta$. No entanto, a 
verossimilhança, ao contrário da probabilidade, não é necessariamente aditiva em relação ao parâmetro, 
de forma de a função $\Psi^\dagger$ não é uma função de verossimilhança:

``No special meaning attaches to any part of the area under a likelihood curve, or to the sum of the likelihoods of two or more
hypotheses (...).
Altough the likelihood function, and hence the curve, has the mathematical form of a [known] distribution, it does not
represent a statistical distribution in any sense.'' \citep{Edwards72}

Em geral, ao determinar regras para combinar o suporte de hipóteses simples para construir uma função de suporte
para hipóteses compostas, estamos considerando funções da forma:

\begin{equation}
\Psi ( \gamma | \bu{x} ) = \int\limits_{g(\theta) = \gamma} \mathcal{L} (\theta | \bu{x}) \kappa(\theta) \,d\theta
\label{eqn:Psi}
\end{equation}

Onde a função $\Psi^\dagger$ é obtida trivialmente com $\kappa(\theta)=1$, e a função $\Psi^\delta$ é um caso-limite
no qual $\kappa(\theta)$ se aproxima de uma função Delta de Dirac. Precisamos examinar as propriedades dessa classe
de funções; examinar se elas se adequam aos requerimentos de uma função de suporte; e investigar a relação entre
a adoção dessas funções e as bases lógicas da inferência, em especial o princípio e a lei da verossimilhança. 
Antes, no entanto, vamos nos defrontar com o problema geral do teste de hipóteses compostas.

\begin{shaded}
\section{Hipóteses compostas}
Como exposto na sessão \ref{sec:likelihood}, a lei da verossimilhança (LL), enunciada por Ian Hacking, se refere a hipóteses
simples:

``If hypothesis $A$ implies that the probability that a random variable $X$ takes the value $x$ is $p_A(x)$, while
hypothesis $B$ implies that the probability is $p_B(x)$, then the observation $X=x$ is evidence supporting $A$ over $B$ 
if and only if $p_A(x) > p_B(x)$, and the likelihood ratio, $p_A(x)/p_B(x)$, measures the strenght of that evidence.''
\citep{Hacking65}

Como, então, trabalhar com hipóteses compostas? A resposta tradicional de verossimilhantistas para essa questão é uma
simples negativa: Edwards descarta hipóteses compostas como ``desinteressantes para a ciência'' \citep{Edwards72},
enquanto Royall enxerga na requisição de que as hipóteses sejam simples um benefício, e não uma falha, da abordagem
por verossimilhança \cite{Royall97}, exemplificado no problema a seguir:

\section{Propriedades de uma função de suporte}
Vamos investigar as seguintes propriedades de uma função de medida de suporte (ver \citep{Edwards72}, sec. 3.2):

\begin{enumerate}
	\item {\em Transitividade}.
	\item {\em Aditividade em relação aos dados}.
	\item {\em Invariância a transformações dos dados}.
	\item {\em Invariância a transformações dos parâmetros}. 
	\item {\em Relevância e consistência}.
	\item {\em Compatibilidade}.
\end{enumerate}



\section{Proposta de aplicação}

Uma metodologia de análise de incerteza baseada em uma função de suporte, após a escolha de uma determinada forma para
a equação de suporte $\Psi(\gamma|\bu{x})$ deve ser dada por:

\begin{enumerate}
	\item Formule diferentes modelos para explicar seus dados (ex, fertilidade constante ou agrupada, taxa de crescimento 
		constante ou descrescente com a classe de tamanho, modelo com 4 ou com 5 classes de tamanho, etc). Escreva a 
		função de verossimilhança $L_i(\bu{\theta}|\bu{x})$ para cada modelo $i \in 1,...,n$.
	\item Encontre o conjunto de parâmetros que melhor ajusta seus dados para cada modelo. 
	\item Determine o valor de AIC para cada modelo. 
	\item Caso haja um modelo cujo desempenho é inequivocamente superior, use o método de Metropolis (forma de Monte Carlo) 
		para gerar amostras a partir da função de verossimilhança do modelo, e combine
		esses valores para gerar uma função de suporte de acordo com a equação \ref{eqn:Psi}. 
	\item Caso haja um empate entre modelos, gere amostras a partir de todos os modelos vencedores e as combine usando 
		os pesos designados pela diferença de informação.
	\item Realize as análises de incerteza e sensibilidade a partir dos resultados gerados.
\end{enumerate}
\end{shaded}
