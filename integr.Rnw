\section{Motivação}
O desenvolvimento e utilização de modelos matemáticos e computacionais deve compreender as seguintes etapas: 
verificação, validação, calibração, análise de incerteza e análise de sensibilidade.

As duas primeiras etapas estão historicamente 
muito interligadas, e costumam ser referidas como V \& V: a verificação consiste em garantir que o código 
computacional implemente o modelo desejado, enquanto a validação consiste em garantir que o modelo teórico é capaz de 
reproduzir os fênomenos reais desejados. Outra forma de pensar em V \& V é que a validação se ocupa em determinar
que o modelo está resolvendo as equações certas, enquanto a verificação se ocupa em determinar se o modelo está
resolvendo as equações corretamente \citep{ASC2010}.
Questões relacionadas a verificação de modelos não costumam ser formuladas estatisticamente, então não serão tratadas aqui.

A calibração consiste em ajustar os parâmetros implementados no código para melhorar a concordância entre o resultado
obtido pelo modelo e aquele observado em uma determinada situação. A correta calibração de um modelo é considerada
essencial para que o modelo possa ser considerado para fins preditivos \citep{ASC2010}.

As duas últimas etapas já foram extensamente discutidas no capítulo \ref{cap:pse}, mas é importante frisar que
é geralmente aceito que a
calibração e as análises de incerteza e sensibilidade dependem fortemente da realização prévia de verificação e 
validação do modelo.

Durante o desenvolvimento e a análise de modelos matemáticos em ecologia, é comum separar a calibração por 
estimativa dos parâmetros (EP)
da análise de incerteza e sensibilidade (AIS) do modelo. Os dois passos são feitos em seções diferentes dos artigos, discutidos
em capítulos diferentes dos livros \citep{Caswell89}, e frequentemente realizados por equipes diferentes. Em estudos que 
empregam modelos matriciais, a discussão dos resultados se concentra no ponto obtido por uma combinação 
de parâmetros considerada ótima durante as estimativas de parâmetros \citep{SilvaMatos99}, e a análise de incerteza é apresentada
como um procedimento separado e posterior à análise do resultado considerado como principal. 
Até mesmo a abordagem estatística usada em ambos os procedimentos pode ser incoerente.

Outro problema que surge nessa abordagem é o fato de que, muitas vezes, o conjunto de parâmetros usados na calibração do modelo
tem pouca relação com as entradas individuais da matriz de projeção. Isso ocorre, por exemplo, quando séries temporais
da população são utilizadas para estimar as taxas vitais: nesse caso, o responsável pela calibração vê o sistema como
contagens de indivíduos, enquanto o responsável pela análise de incerteza tipicamente realiza a análise sobre as taxas vitais.
Desta forma, a AIS é incapaz de apontar rumos para o planejamento de novos experimentos, apontando quais parâmetros 
devem ser alvo de maior esforço de coleta.

Essa falta de integração entre os passos necessários para o estudo de um modelo tem suas raízes no 
desenvolvimento das teorias de EP e AIS. Enquanto a estimação de parâmetros sempre foi tratada sob o ponto de vista
de uma teoria estatística, a análise de sensibilidade de modelos matriciais foi desenvolvida como 
uma ferramenta analítica, baseada em expansões lineares das funções de interesse em torno de um ponto privilegiado. 
Dependendo do tipo de experimento utilizado para obter estimativas das taxas vitais, diferentes abordagens 
podem ser utilizadas para encontrar um conjunto de valores que melhor represente o estado de conhecimento
que temos de uma população, entre abordagens frequentistas, bayesianas ou baseadas em verossimilhança.
Já a teoria analítica de AIS, devida em grande parte aos trabalhos de Hal Caswell (por exemplo \citep{Caswell89}), 
procede rotineiramente por
tomar um modelo já parametrizado da forma ótima, e estudar as derivadas de primeira ordem da resposta de interesse
em relação a cada um dos parâmetros de entrada. Nessa formulação, a quantidade e a qualidade dos dados de entrada
para o modelo são ignorados, a menos de suas médias, e medidas de sensibilidade são tomadas exclusivamente sobre
a variação da resposta de interesse a perturbações infinitesimais. Desta forma, modelos parametrizados com dados
com grande incerteza não apresentarão grandes medidas de sensibilidade, assim como aumentar o esforço amostral não
reduzirá necessariamente as medidas de incerteza. A análise de sensibilidade analítica, em última análise, diz
respeito à estrutura do modelo matricial, e não ao procedimento completo desde a tomada de dados em campo até
a formulação e execução do modelo. Isso pode levar a uma falsa confiança em estudos que apresentem
uma estrutura matricial estável, portanto de baixas sensibilidades, mas dados tomados com muita incerteza.

Por outro lado, questões de validação dos modelos são frequentemente menosprezadas pela literatura da área,
apesar de estarem intimamente conectadas com as questões relevantes de incerteza. Podemos dividir a incerteza
de um modelo em três fontes principais: incerteza estrutural, incerteza de parâmetros (ou epistêmica) 
e incerteza estocástica. Enquanto a maioria das técnicas de AIS se concentram na segunda componente, 
a validação de modelos pode apontar qual o nível de confiança que podemos ter de que um dado modelo é
o modelo correto para reproduzir o fenômeno visto.

A formulação estocástica da teoria de análise de incerteza e sensibilidade global, como descrita no capítulo \ref{cap:pse}, 
e interpretada dentro de uma
abordagem pautada pelo princípio da verossimilhança, é capaz de contemplar da mesma forma todas as fontes de 
incerteza descritas acima, gerando como resultado um quadro completo do nosso conhecimento a respeito de 
um sistema. 
Embora para sistemas muito simples as abordagens possam convergir, isso não se verifica para problemas
e sistemas de maior complexidade. As principais vantagens de usar a formulação estocástica são:

\begin{enumerate}
	\item A abordagem analítica é local (portanto, responde ao que acontece com perturbações infinitesimais) 
		e depende das funções serem "suaves" na vizinhança, a estocástica é global e não tem essa limitação.
	\item Uma abordagem estocástica (baseada ou não na verossimilhança) permite que a informação contida na 
		variabilidade amostral seja utilizada para representar a incerteza sobre os parâmetros (veja seção \ref{Sampling}).
	\item O princípio de verossimilhança afirma que toda a informação contida nas amostras coletadas está contida 
		na função de verossimilhança. Dessa forma, a análise de sensibilidade feita a partir da função de 
		verossimilhança contém toda a informação obtida pela amostra e nenhuma informação além da obtida pela 
		amostra - enquanto a abordagem analítica e outras formulações estocásticas
		podem, alternadamente, desperdiçar informações coletadas ou 
		levar à falsa impressão de gerar respostas com maior precisão do que a informação coletada permite. 
		% PI: aqui há dois aspectos: o uso da informação de incerteza ou variância contida na amostra, o que pode ser feito de várias maneiras, e justificar o uso da funçãod e verosimilhnaça como a maniera mais adequada de se fazer isso. 
		% C: inclui o item 2 pra separar
\end{enumerate}

\section{Uma função de suporte}
Ao falar da análise de incerteza de um modelo matemático sob o paradigma da verossimilhança, a pergunta que estamos
fazendo pode ser escrita como: ``qual o suporte que existe para hipóteses concorrentes a respeito do resultado de um
modelo, a partir de um conjunto de dados coletados?''. Em um modelo de crescimento populacional, por exemplo, a pergunta
se torna ``qual o suporte que os dados coletados fornecem para a hipótese de que a população está crescendo ou estável,
{\em versus} a hipótese de que a população está em declínio?''.

Vamos considerar problemas onde $\bu{x}$ representa um vetor de dados obtidos de forma independente
em um ou mais experimentos a partir de uma variável aleatória $\bu{X}$, tal que $P(\bu{X}\!=\!\bu{x}) = f(\bu{x};\theta)$. 
O parâmetro
(ou vetor de parâmetros) $\theta$ é desconhecido e pode assumir valores em $\Theta$. A verossimilhança de $\theta$
dadas as observações $\bu{x}$ é dada por $\mathcal{L} (\theta | \bu{x}) = f(\bu{x}; \theta)$. A razão de verossimilhanças
sob o mesmo conjunto de dados pode ser abreviada como $L(\theta_1, \theta_2) = \frac{\mathcal{L}(\theta_1|\bu{x})}
{\mathcal{L}(\theta_2|\bu{x})}$. 
% PI: qual o propósito deste parágrafo? C: estabelecer a notação. Mudei para essa seção para ficar + natural

Sabemos que essa pergunta, se formulada sobre os parâmetros
de uma distribuição de probabilidade, é respondida através da função de verossimilhança. Também sabemos que
transformações injetoras sobre parâmetros preservam as propriedades da função de verossimilhança, isso é: 
se um parâmetro $\theta$ está associado a uma função de verossimilhança $\mathcal{L}(\theta|\bu{x})$ e 
$\phi = f(\theta)$ é dada por uma função $f(\cdot)$ injetora, a verossimilhança de $\phi$ é dada simplesmente por
$\mathcal{L}(\phi|\bu{x}) = \mathcal{L} \left(f(\theta)|\bu{x}\right)$ (\citep{Edwards72}, sec. 2.5).

Nosso trabalho, então, é o de estender esse resultado para uma função genérica. 
Nosso argumento se baseia em uma função de um argumento, $\gamma = g(\theta)$, sendo que a generalização 
para mais dimensões é trivial.\footnote{A notação usada aqui é mais compatível com a literatura estatística,
enquanto na seção \ref{PSE}, definimos as entradas, resultados e o modelo em si como $x$, $y$ e $f$, relacionados
como $y = f(x)$, aqui podemos pensar nesses objetos como $\theta$, $\gamma$ e $g$, respectivamente.}

O problema de definição de uma verossimilhança para análise de incerteza em modelos está, portanto, intimamente ligada à questão
de hipóteses estatísticas compostas. O trabalho fundamental de Neyman e Pearson \citep{Neyman1933}
estabelece uma justificativa matemática para o princípio da verossimilhança em problemas envolvendo hipóteses simples.
O problema de hipóteses compostas é resolvido dentro do paradigma frequentista para alguns casos particulares, como 
o teste {\em t de Student}, que avalia a hipótese nula de que a média de duas populações é igual, sendo a variância um 
parâmetro desconhecido. Estatísticos frequentistas tratam o problema de hipóteses compostas através do máximo de
verossimilhança obtido por qualquer de suas hipóteses simples componentes. Muito do trabalho nessa área se concentrará
em encontrar aproximações para a distribuição dessa estatística \citep{Wilks38}.

Sob esta inspiração, vamos construir uma função tentativa de suporte $\Psi^\delta (\gamma | \bu{x})$, definida por:

\begin{equation}
	\Psi^\delta ( \gamma | \bu{x} ) = \sup\limits_{g(\theta) = \gamma} \mathcal{L} (\theta | \bu{x})
\label{eqn:Psidelta}
\end{equation}

Essa função pode ser intuitivamente interpretada no sentido de equiparar a verossimilhança da hipótese composta com
a da sua melhor hipótese simples componente.
Para clarificar nossa operação, vamos construir uma outra função a partir de $\mathcal{L}(\theta|\bu{x})$ que 
\textbf{não} é função de verossimilhança: $\Psi^\star (\gamma | \bu{x})$, definida por:
\begin{equation}
\Psi^\star ( \gamma | \bu{x} ) = \int\limits_{g(\theta) = \gamma} \mathcal{L} (\theta | \bu{x}) \,d\theta
\label{eqn:Psistar}
\end{equation}

Intuitivamente, podemos considerar que se dois valores de $\theta$ levam a um mesmo valor de $\gamma$, a equação \ref{eqn:Psistar}
nos diz que o suporte para esse valor de $\gamma$ seria a soma do suporte dado aos valores de $\theta$.
Enquanto a função \ref{eqn:Psidelta} tem uma forte inspiração nos trabalhos frequentistas, a função \ref{eqn:Psistar}
vem de uma inspiração Bayesiana. No entanto, a 
verossimilhança, ao contrário da probabilidade, não é necessariamente aditiva em relação ao parâmetro, 
de forma de a função $\Psi^\star$ não é uma função de verossimilhança:

\begin{quote}
``No special meaning attaches to any part of the area under a likelihood curve, or to the sum of the likelihoods of two or more
hypotheses (...).
Altough the likelihood function, and hence the curve, has the mathematical form of a [known] distribution, it does not
represent a statistical distribution in any sense.'' \citep{Edwards72}
\end{quote}

Em geral, ao determinar regras para combinar o suporte de hipóteses simples para construir uma função de suporte
para hipóteses compostas, estamos considerando funções da forma:

\begin{equation}
\Psi ( \gamma | \bu{x} ) = \int\limits_{g(\theta) = \gamma} \mathcal{L} (\theta | \bu{x}) \kappa(\theta) \,d\theta
\label{eqn:Psi}
\end{equation}
% PI: isto é MUITO legal! C: Agradeça a Mali, que me ajudou a montar esse quebra-cabeça =D
Onde a função $\Psi^\star$ é obtida trivialmente com $\kappa(\theta)=1$, e a função $\Psi^\delta$ é um caso-limite
no qual $\kappa(\theta)$ se aproxima de uma função Delta de Dirac. Precisamos examinar as propriedades dessa classe
de funções; examinar se elas se adequam aos requerimentos de uma função de suporte; e investigar a relação entre
a adoção dessas funções e as bases lógicas da inferência, em especial o princípio e a lei da verossimilhança. 
\cite{Edwards72} enumera as seguintes propriedades desejáveis em uma função de medida de suporte:

\begin{enumerate}
	\item {\em Transitividade}: Se $H_1$ tem melhor suporte que $H_2$ e $H_2$ tem melhor suporte que $H_3$, então
		$H_1$ deve ter melhor suporte que $H_3$.
	\item {\em Aditividade em relação aos dados}: o suporte relativo entre duas hipóteses deprendido de uma
		observação deve ser facilmente combinável com o suporte relativo para as mesmas hipóteses deprendido
		de uma observação diferente.\footnote{Edwards usa ``aditividade'' sobre a log-verossimilhança, equivalentemente medidas
		de verossimilhança podem ser combinadas de forma multiplicativa.}
	\item {\em Invariância a transformações injetoras dos dados}.
	\item {\em Invariância a transformações injetoras dos parâmetros}. 
	\item {\em Relevância e consistência}: se uma hipótese for verdadeira, ela deve receber mais suporte do que hipóteses
		concorrentes no longo termo. O suporte relativo deve ser coerente entre diversos problemas: o mesmo valor de
		suporte relativo deve ter o mesmo significado.
	\item {\em Compatibilidade}: uma medida de suporte deve ser facilmente usada para atualizar informações na forma de
		{\em prioris}, nos casos nos quais elas existam.
\end{enumerate}

\section{Hipóteses compostas}
Como exposto na seção \ref{sec:likelihood}, a lei da verossimilhança (LL, do inglês Law of Likelihood),
enunciada por Ian Hacking, se refere a hipóteses simples:

\begin{description}
\item[LL]
``If hypothesis $A$ implies that the probability that a random variable $X$ takes the value $x$ is $p_A(x)$, while
hypothesis $B$ implies that the probability is $p_B(x)$, then the observation $X=x$ is evidence supporting $A$ over $B$ 
if and only if $p_A(x) > p_B(x)$, and the likelihood ratio, $p_A(x)/p_B(x)$, measures the strenght of that evidence.''
\citep{Hacking65}
\end{description}

Como, então, trabalhar com hipóteses compostas? A resposta tradicional de verossimilhantistas para essa questão é uma
simples negativa: Edwards descarta hipóteses compostas como ``desinteressantes para a ciência'' \citep{Edwards72},
enquanto Royall enxerga na requisição de que as hipóteses sejam simples um benefício, e não uma falha, da abordagem
por verossimilhança \citep{Royall97}, exemplificado no problema a seguir:

Suponha que um grupo de pesquisadores da área médica realizam um experimento para determinar a probabilidade de sucesso
de um certo tratamento. Eles estão particularmente interessados em descobrir se o novo tratamento tem mais probabilidade de 
sucesso do que 0.2, que representa a probabilidade de sucesso de um tratamento concorrente. Após aplicar o novo tratamento
em 17 pacientes, eles encontram sucesso em 9. O que esse resultado pode dizer sobre as hipóteses?

Uma análise frequentista vai confrontar a hipótese nula $H_0: \theta = 0.2$, e concluir que a probabilidade de encontrar
9 ou mais sucessos em 17 realizações de um processo Bernoulli com $p=0.2$ é de aproximadamente 0.04\%, rejeitando a hipótese.

Uma análise Bayesiana vai considerar as hipóteses $H_1:\theta \leq 0.2$ versus $H_2: \theta > 0.2$. O estatístico Bayesiano
deve escolher uma forma para representar seu conhecimento prévio, e pode, por exemplo,
usar a {\em priori} uniforme, dada por $B(1,1)$, como feito por Bayes, encontrando uma {\em posteriori}
igual a $B(10,9)$, ou uma {\em priori} de Jeffreys, dada por $B(\frac{1}{2},\frac{1}{2})$, encontrando uma {\em posteriori}
de $B(9.5, 8.5)$. Ambas as análises levam a probabilidades muito baixas para $H_1$: 0.09\% e 0.11\%, respectivamente.

Ainda, a razão de verossimilhança entre o estimador de máxima verossimilhança para $\theta = 0.52$ e qualquer hipótese
simples $H_p:\theta=p , \, p \leq 0.2$ é de no mínimo 91.5. Todos esses cálculos sugerem que os dados sejam coerentes com
a hipótese de maior suporte ser aquela que considera que o novo tratamento tem probabilidade de sucesso maior do que 0.2.

No entanto, a lei da verossimilhança de Hacking não permite essa afirmação, pois $H_1$ e $H_2$ não são hipóteses que
atribuam um único valor de probabilidade às observações da variável aleatória sob consideração. Royall aponta que, embora
algumas hipóteses simples componentes de $H_1$ sejam melhor suportadas do que as componentes de $H_2$, isso não é válido em
geral: a hipótese $\theta = 0.2$ é mais suportada do que $\theta=0.9$ por um fator de 22.

É importante notar que
isso não é uma consequência da formulação das hipóteses envolvendo desigualdades, de fato as hipóteses $H^\dagger_1 : \gamma = 0$
e $H^\dagger_2 : \gamma = 1$ são equivalentes, e tão intratáveis quanto, as hipóteses $H_1$ e $H_2$, com $\gamma$ sendo dado por

\begin{equation}
	\gamma = \left\{ 
	\begin{array}{c c}
		0, & \theta \leq 0.2 \\
		1, & \theta > 0.2 
	\end{array}
	\right.
\end{equation}

Embora o uso de hipóteses compostas seja necessário para tratar hipóteses formuladas a respeito do resultado de modelos,
pouco progresso se fez na elaboração de uma lei da verossimilhança que se aplique a hipóteses compostas. Os caminhos que podem
ser trilhados aqui são:

\begin{enumerate}
	\item Tratar a questão através da modelagem de {\em nuisance parameters}; \label{i:prof}
	\item Formular uma lei da verossimilhança que seja aplicável a hipóteses compostas;\label{i:alt}
	\item Apresentar uma metodologia baseada em uma extensão lógica da lei da verossimilhança.\label{i:ext}
\end{enumerate}

A proposta \ref{i:prof} se baseia em métodos como a verossimilhança perfilhada e a verossimilhança condicional, que são
propostas {\em ad hoc} usadas para reduzir o estudo de modelos estatísticos multiparamétricos a um parâmetro por vez.
Um uso típico é dado ao ajustar uma distribuição normal a uma série de dados: embora, estritamente, as hipóteses que possam
ser comparadas sejam dadas por pares $(\mu = \mu_0, \sigma = \sigma_0)$ 
representando um valor fixo para a média e desvio padrão dessa normal, 
é possível comparar uma aproximação para suporte relativo para diferentes valores para a média, com o desvio padrão livre
- portanto, caracterizando a hipótese composta $(\mu = \mu_0, \sigma \geq 0)$.
Para alguns casos de hipóteses compostas, é possível descrever uma transformação de parâmetros que permita essa abordagem;
no entanto uma teoria geral para tratar hipóteses compostas baseada nessas técnicas parece improvável.

% PI: Ainda não está claro para mim que analisar a função de verossimilhança com muito parâmetros (e.g. por meio de perfilhamento) é o mesmo problema que construir hipóteses compostas. Lembre-se de me explicar esta parte.
% C: Na verdade, eh um caso particular que funciona bem para algumas hipoteses compostas, dei uma explicada acima.
A proposta \ref{i:alt} se baseia na formulação axiomática de uma lei geral, GLL (do inglês Generalized Law of Likelihood),
que seja compatível com a lei da verossimilhança LL
para hipóteses simples, mas que extenda seu domínio para hipóteses compostas. Em contraste, a proposta \ref{i:ext} 
propõe utilizar uma definição mais fraca de evidência, baseada em uma lei fraca da verossimilhança (WLL, do inglês
Weak Law of Likelihood), tal que aceitar LL implique em aceitar WLL, mas a conversa não seja verdadeira.

\section{Uma lei geral de verossimilhança}

Talvez a generalização mais óbvia para a lei da verossimilhança para hipóteses compostas seja tomar o máximo (ou supremo,
no casos em que o máximo não existe) da verossimilhança de suas hipóteses simples. Esse é o caminho perseguido por
\cite{Zhang09, Zhang13} e \cite{Bickel10}, por exemplo. Zhang considera duas hipóteses, $H_1 : \theta \in \Theta_1 \subset \Theta$
versus $H_2 : \theta \in \Theta_2 \subset \Theta$, e postula os seguintes axiomas (levemente modificados para coerência
com a notação):

\begin{axiom}
	Se $\inf \mathcal{L}(\Theta_1 | \bu{x}) > \sup \mathcal{L} (\Theta_2 | \bu{x})$, então a observação $\bu{x}$ 
	é uma evidência a favor de $\Theta_1$.\label{ax:inf}
\end{axiom}

\begin{axiom}
	Se $\bu{x}$ é evidência a favor de $H_1^*$ em relação a $H_2$ e $H_1^*$ implica em $H_1$, então $\bu{x}$ é evidência de 
	$H_1$ sobre $H_2$.\label{ax:coh}
\end{axiom}

O primeiro axioma estabelece que se a imagem de $\mathcal{L} (\Theta_1|\bu{x})$ e $\mathcal{L} (\Theta_2|\bu{x})$ são intervalos
disjuntos, portanto, se toda hipótese simples que implica em $H_1$ é suportada {\em versus} toda hipótese simples que implica
em $H_2$, então $H_1$ é suportada {\em versus} $H_2$. Não parece haver motivo para rejeitar esse axioma, além de uma
indisposição prévia a tratar hipóteses compostas. Já o segundo axioma é uma forma de estabelecer coerência lógica.
É importante clarificar que esse requisito de coerência {\em não é} equivalente a supor que a estrutura lógica das hipóteses
deve ser usada como base para justificar um grau de crença sobre $H_1^*$ ou $H_1$: se $H_1^*$ implica em $H_1$ e a recíproca
não é verdadeira, o axioma \ref{ax:coh} {\em não} justifica que $H_1^*$ seja melhor suportada que $H_1$ por qualquer evidência.
Destes axiomas, deriva-se uma lei geral da verossimilhança:

\begin{theorem}
	\textbf{(GLL)} Se $\sup \mathcal{L} (\Theta_1 | \bu{x} ) > \sup \mathcal{L} (\Theta_2 | \bu{x})$, então existe evidência
	a favor de $H_1$ sobre $H_2$.
\end{theorem}

\begin{proof}
	Seja $\sup \mathcal{L} (\Theta_1 | \bu{x} ) > \sup \mathcal{L} (\Theta_2 | \bu{x})$. Então existe $\theta_1 \in \Theta_1$
	tal que $\mathcal{L} (\theta_1 | \bu{x}) > \sup \mathcal{L} (\Theta_2 | \bu{x})$. Do axioma \ref{ax:inf}, a hipótese
	$H_1^* : \theta = \theta_1$ é suportada em relação a $H_2$. Mas $H_1^*$ implica $H_1$, e a conclusão segue do axioma
	\ref{ax:coh}.
\end{proof}

Embora não decorra dos axiomas, o uso de uma razão de verossimilhança generalizada $\sup \mathcal{L}(\Theta_1 | \bu{x}) / 
\sup \mathcal{L} (\Theta_2 | \bu{x}) $ parece natural para quantificar a força da evidência. É trivial que GLL é 
compatível com LL no caso de hipóteses simples, e com alguns casos particulares expostos por \citep{Royall97}. Essa formulação
da GLL pode ser usada para apresentar questões de análise de incerteza e para formalizar o uso de verossimilhanças perfilhadas
em alguns casos de modelos com {\em nuisance parameters}. 

No entanto, a implicação mais surpreendente da GLL é que ela permite uma medida de confirmação {\em absoluta} de hipóteses.
Uma hipótese  $H_1: \theta \in \Theta_1$ possui evidência favorável se $\sup \mathcal{L}(\Theta_1|\bu{x}) > 
\sup \mathcal{L} (\Theta_1^c|\bu{x}$, onde $^c$ representa o conjunto complementar, ou $L(\Theta_1, \Theta_1^c) > 1$.
Embora esse suporte seja nulo no caso
de hipóteses simples sobre parâmetros contínuos, esse não é caso quando $\Theta$ é finito.

Considere um exemplo, dado por \cite{Royall97}: 

Existem três urnas com bolas brancas em diferentes proporções: um quarto ($\theta_1$), metade ($\theta_2$) e 
três quartos ($\theta_3$); identificamos como $H_i$ as três urnas possíveis.
Se nenhuma bola branca for observada após 5 sorteios com reposição, essa observação, $\bu{x}$, implica que
$\mathcal{L} (\theta_1 | \bu{x} ) \propto (\frac{3}{4})^5$,
$\mathcal{L} (\theta_2 | \bu{x} ) \propto (\frac{1}{2})^5$ e
$\mathcal{L} (\theta_3 | \bu{x} ) \propto (\frac{1}{4})^5$.

A LL nos permite afirmar que $L(\theta_1, \theta_2) = 7.6$ é evidência mediana a favor de $H_1$ sobre $H_2$, e 
$L(\theta_2, \theta_3) = 32$ é evidência forte de $H_2$ sobre $H_3$. No entanto, a LL não permite inferências sobre a hipótese
composta $H_c : \theta=\theta_1 \lor \theta=\theta_3$ em comparação com $H_2$; equivalentemente, LL não permite
inferências sobre a evidência absoluta $H_2$ sobre $\sim\!\! H_2$.

Por outro lado, a GLL permite a afirmação de que $L(\theta_1 \lor \theta_3, \theta_2) = 7.6$ representa suporte para $H_c$ em
relação a $H_2$, e ainda que
o suporte absoluto para as três hipóteses é de 
$L(\theta_1, \sim\!\! \theta_1) = 7.6$,
$L(\theta_2, \sim\!\! \theta_2) = 0.13$,
$L(\theta_3, \sim\!\! \theta_3) = 0.004$, confirmando que apenas a hipótese 1 tem força de evidência superior a 1.

Uma desvantagem em aceitar a GLL é que o suporte a hipóteses compostas não se comporta da mesma forma que a razão
de verossimilhanças para hipóteses simples. Suponha que o pesquisador, no mesmo problema das urnas, retira agora duas
bolas brancas. Essa nova observação leva aos resultados 
$L(\theta_1, \sim\!\! \theta_1) = 0.11$,
$L(\theta_2, \sim\!\! \theta_2) = 0.44$,
$L(\theta_3, \sim\!\! \theta_3) = 2.25$, oferecendo suporte apenas para $H_3$. No entanto, não há como combinar essa
evidência com a apresentada acima: as quantidades derivadas do supremo da verossimilhança não são multiplicativas para conjuntos
de dados distintos, ao contrário da verossimilhança. 
% PI: Intuição: se o problema é apenas esse pode existir uma outra operação de conjuntos que faça o papel da multiplicação para as hipóteses simples. Faz sentido?
% C: O problema "basal" é que não dá pra descrever essa operação em relação ao *resultado* da verossimilhança. Pra poder combinar os dados sob nova evidência, é preciso ter acesso a função de verossimilhança de theta
A força de evidência absoluta para $\theta_1$ tomando o conjunto completo 
de dados é de aproximadamente $1.8 \neq 7.6 * 0.11$.
Essa constatação, no entanto, não invalida o teorema da GLL, embora
lance dúvidas quanto à aplicabilidade da razão de verossimilhança generalizada como força de evidência para hipóteses compostas.

Em um desenvolvimento independente, o estatístico indiano Debabrata Basu propôs uma generalização
alternativa para a lei da verossimilhança em 1975:
\begin{quote}
``{\em The strong law of likelihood}: For any two subsets $A$ and $B$ of $\Theta$, the data supports the 
hypothesis $\omega \in A$ better than the hypothesis $\omega in B$ if
\begin{equation}
\sum_{\omega \in A} \mathcal{L}(\omega) > \sum_{\omega \in A} \mathcal{L}(\omega)
\end{equation}
Let us recall the [assertion] that all our sets (the sample space, the parameter space, etc.) are finite.''
\end{quote}\citep{Basu75}

\section{Uma lei fraca de verossimilhança}

Confrontados com os insucessos de trabalhar com a verossimilhança de hipóteses compostas e os problemas derivados
de uma medida absoluta de confirmação, os principais defensores da lei da verossimilhança viram por bem abandonar a 
consideração de hipóteses compostas. O outro curso de ação que podemos tomar é abandonar a lei da verossimilhança,
e é o caminho que vamos seguir nesta seção. % PI: isso é o mesmo que fomular uma lei fraca?

Um exemplo devido a Branden Fitelson \cite{Fitelson07} mostra uma questão importante sobre a lei da verossimilhança:
tome um baralho de 52 cartas bem embaralhado, e considere as hipóteses (simples) 
$H_1$: a primeira carta é o ás de espadas {\em versus}
$H_2$: a primeira carta é preta. A observação de uma carta de espadas leva às seguintes verossimilhanças: 
$\mathcal{L} ( H_1 | \spadesuit ) = k 1 > \mathcal{L} ( H_2 | \spadesuit ) = k \frac{1}{2}$, sendo $k$ uma constante de 
proporcionalidade, e a lei da verossimilhança nos leva a declarar o suporte para $H_1$ sobre $H_2$. Mas a evidência apresentada
sobre $H_1$ é inconclusiva, mas garante $H_2$. Fitelson traça essa discordância na relação entre os chamados ``{\em catch-alls}'',
$P(E | \sim\!\!H_1)$ e $P(E|\sim\!\!H_2)$\footnote{Em casos de cartas de baralhos, os {\em catch-alls} estão bem definidos;
objetivistas podem ter problemas em aceitar a formulação de {\em catch-alls} em problemas mais gerais, como "essa observação
provê suporte à teoria da evolução"}. Uma formulação mais geral sobre a lei da verossimilhança, apelidada por J. Joyce de
lei fraca da verossimilhança (WLL) é dada por:

\begin{description}
\item[WLL]
``Evidence $E$ favors hypothesis $H_1$ over hypothesis $H_2$ {\em if} $P(E|H_1) > P(E|H_2)$ {\em and}
$P(E|\sim\!\!H_1) \leq P(E|\sim\!\!H_2)$.''
\citep{Fitelson07}
\end{description}

É evidente que LL $\implies$ WLL. No entanto, as principais correntes de Bayesianismo moderno {\em também} aceitam WLL: dada uma
medida de confirmação $c(H,E)$, a expressão Bayesiana equivalente a LL é:

\begin{description}
\item[$\dagger_c$]
``Evidence $E$ favors hypothesis $H_1$ over hypothesis $H_2$ according to measure $c$ {\em iff} $c(H_1,E) > c(H_2,E)$.''
\citep{Fitelson07}
\end{description}

Três possíveis formas para a medida de confirmação são:
\begin{description}
\item[Diferença] $d(H,E) = P(H|E)-P(H)$
\item[Razão] $r(H,E) = \frac{P(H|E)}{P(H)}$
\item[Razão de verossimilhanças] $l(H,E) = \frac{P(E|H)}{P(E|\sim\!\!H)}$
\end{description}

É importante relembrar que a confirmação Bayesiana dada por $c(H,E)$ 
tem um caráter não-relacional, à partir do qual se {\em deriva} uma 
medida de confirmação relacional; verossimilhantistas enxergam na lei da verossimilhança uma relação primitiva.
E enquanto a construção da medida de confirmação não-relacional depende da especificação de {\em prioris}, a WLL não faz uso 
direto deles, mas apenas da especificação de {\em catch-alls}. Uma teoria que utilizasse a WLL sem invocar {\em prioris}
poderia embasar uma escola de inferência intermediária, sem o uso de {\em prioris} ao qual objetivistas objetam, 
nem a restrição
arbitrária ao tratamento de hipóteses compostas.

%O paradigma da verossimilhança parece estar encravado dentro do pensamento Bayesiano: se generalizamos a Lei da Verossimilhança,
%nos encontramos em um paradigma Bayesiano; se a enfraquecemos, encontramos todas as correntes do Bayesianismo moderno.
%Se o problema da inferência estatística é respondido pela Lei da Verossimilhança, essa resposta deve passar por explicar
%essa singularidade.

% PI: Faz sentido esta especulação

% \section{Proposta de aplicação}
% PI: A proposta faz sentido para mim, mas depois de ler as seções anteriores fiquei em dúvida sobre a interpretação. Creio que isso acontece porque ainda não há uma ligação clara entre a teoria das seções anteriores a aplicação e exemplos que começma aqui, confere?
% C: Verdade. Fiquei mto em dúvida sobre colocar ou não essa seção aqui; estou retirando ela para a quali, depois volto a inseri-la qndo tiver a teoria mais clara. Vou tb deixar mais claro que as aplicações nas proximas sessoes NÃO foram feitas dentro desse  paradigma ainda.

%Uma metodologia de análise de incerteza baseada em uma função de suporte, após a escolha de uma determinada forma para
%a equação de suporte $\Psi(\gamma|\bu{x})$ deve ser dada por:

%\begin{enumerate}
%	\item Formule diferentes modelos para explicar seus dados (ex, fertilidade constante ou agrupada, taxa de crescimento 
%		constante ou descrescente com a classe de tamanho, modelo com 4 ou com 5 classes de tamanho, etc). Escreva a 
%		função de verossimilhança $L_i(\bu{\theta}|\bu{x})$ para cada modelo $i \in 1,...,n$.
%	\item Encontre o conjunto de parâmetros que melhor ajusta seus dados para cada modelo. 
%	\item Determine o valor de AIC para cada modelo. 
%	\item Caso haja um modelo cujo desempenho é inequivocamente superior, use o método de Metropolis (forma de Monte Carlo) 
%		para gerar amostras a partir da função de verossimilhança do modelo, e combine
%		esses valores para gerar uma função de suporte de acordo com a equação \ref{eqn:Psi}. 
%	\item Caso haja um empate entre modelos, gere amostras a partir de todos os modelos vencedores e as combine usando 
%		os pesos designados pela diferença de informação.
%	\item Realize as análises de incerteza e sensibilidade a partir dos resultados gerados.
%\end{enumerate}

% PI: Tive dificuldades de identificar estes passos nos exemplos. No
% modelo mínimo me parece que há um só modelo, portanto os passos 1, 3
% e 5 não se aplicam? Ainda assim, me parece ter sentido após o ajuste
% fazer a análise de incerteza e sensisbilidade amostrando-se a
% superfície de verossimilhança como você fez. No caso do Tribolium vc
% não usou este procedimento, apenas o hipercubo para investigar numa
% vizinhança definida por uma distribuiçãod e probabilidades, correto?
% Novamente faz sentido, mas falta conectar teoria com exemplos de
% alguma maneira. Um caminho é separar a proposta em duas partes:
% exploração estocástica (contra análise local por aproximação linear,
% no caso de modelos matriciais); e exploração estocástica baseada na
% inceerteza das estimativas, expressa pela função de
% verossmilhança. Me lembre de discutirmos isso.

% C: Fato, os passos 1 3 e 5 desaparecem caso só haja um modelo para a geração dos dados.
% O Tribolium estah feito como descrito no cap. 2, ainda nao consegui montar a pse verossim. pra ele
